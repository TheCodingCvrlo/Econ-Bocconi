##### ECONOMETRICS ASSIGNMENT Y21/22 ####

# Giovanni Gatti - 3121689
# Antonio Ventura - 3127698
# Carlo Antonio Patti - 3134395


########################################### TAYLOR RULE IN AUSTRALIA ####################################################

# Clearing the workspace
rm(list=ls())

# Getting the path of your current open file
current_path = rstudioapi::getActiveDocumentContext()$path
current_dir = dirname(current_path)

setwd(current_dir )


# installing / importing libraries
# install.packages('tseries')
# install.packages('tidyverse')
library(ggplot2)
library(lmtest)
library(tseries)
library(tidyverse)



##################################### DATA PREPARATION ####################################

# importing data

# output <- read.csv(paste(dirname(current_path),'australia_gdp.csv',sep = '/'))
# rates <- read.csv(paste(dirname(current_path),'short_term_interest_rates.csv',sep = '/'))
# inflation <- read.csv(paste(dirname(current_path),'inflation.csv',sep = '/'))
# out_gap <- read.csv(paste(dirname(current_path),'inflation.csv',sep = '/'))
# 
# out_gap = select(out_gap,TIME,Value)
# rates = select(rates, TIME, Value)
# 
# #renaming columns
# colnames(inflation) <- c('YEAR', 'INF')
# colnames(output) <- c('YEAR', 'GDP')
# colnames(rates) <- c('YEAR', 'RATE')
# colnames(out_gap) <- c('YEAR', 'GAP')
# 
# #setting cutoff
# output <- output[output$YEAR > 1984,]
# inflation <- inflation[inflation$YEAR > 1984,]
# rates <- rates[rates$YEAR > 1984,]
# 
# # rescaling GDP (from USD to Billion USD)
# output$GDP = output$GDP/1000000000
# 

#merging data in one dataframe

# df <- list(rates, output, inflation,out_gap)
# df = df %>% reduce(full_join, by = 'YEAR')
# 
# write.csv(df, paste(clean_path,'\\df_final.csv',sep = ''))

df <- read.csv(paste(dirname(current_path),'df_final.csv',sep = '/'))


################################## MODEL #######################################

#  i_t = b1 + b2* pi_t + b3* y_t + eps

# DEPENDENT VARIABLE

# i_t - policy rate in Australia in year t

# INDEPENDENT VARIABLES

# pi_t - inflation (CPI percentage change) from year t to year t+1
# y_t - output (GDP) in year t

#INTERCEPT

# b1 captures equilibrium interest rate, inflation target and any other deviation in the mean of our model


############################# PLOTTING RAW DATA #########################################


# GDP/YEAR
ggplot(df, aes(x = YEAR, y  = GDP)) + 
  geom_point() + 
  labs(
    title = 'Australian GDP 1980-2021',
    x = ''
  ) +
  stat_smooth(method = 'lm', formula = y~x, alpha = 0.2)



# POLICY RATE/YEAR
ggplot(df, aes(x = YEAR, y  = RATE)) + 
  geom_point() + 
  labs(
    title = 'Policy Rates 1980-2020',
    x = '',
    y = 'Interest Rate'
  ) +
  stat_smooth(method = 'lm', formula = y~x)

# INFLATION/YEAR
ggplot(df, aes(x = YEAR, y  = INF)) + 
  geom_point() + 
  labs(
    title = 'CPI-measured Inflation 1980-2020',
    x = '',
    y = 'Inflation Rate (%)'
  ) +
  stat_smooth(method = 'lm', formula = y~x)

#OUT GAP/ YEAR

ggplot(df, aes(x = YEAR, y  = GAP)) + 
  geom_point() + 
  labs(
    title = 'Output Gap as % of Potential Output',
    x = '',
    y = 'Output Gap'
  ) +
  geom_smooth(formula = y~x)





################################ OLS ESTIMATION ######################################

taylor_reg <- lm(RATE ~ GDP + INF, data = df)

summary(taylor_reg)
coeftest(taylor_reg)

ggplot(df) + 
  aes(x = YEAR) + 
  geom_point(aes(y = RATE)) + 
  geom_point(aes(y = fitted(taylor_reg)),color = 'red')

#plotting distribution of residuals

res <- residuals(taylor_reg)

res = data.frame(res)
res$ind = rep(1:36)

ggplot(res) +
  aes(x = res) + 
  geom_histogram(aes(y = stat(count) / sum(count)), colour = 'black', fill = 'white',bins = 10) + 
  geom_density(alpha = .3, fill = "#FF6666",size = 1) + 
  labs(
    title = 'Residuals',
    x = 'Residual Value',
    y = 'Relative Frequency'
  )

############################ TESTING MODEL ASSUMPTIONS ################################

# TODO: complete, explain


#Testing Linearity of Parameters
resettest(taylor_reg,power = 2:3, type="fitted")

#H0 is accepted with pval = 0.1217


#Jarque-Bera Test for Normality of Residuals
jarque.bera.test(residuals(taylor_reg))     
#H0 is accepted with pval = 0.618


# Testing Homoscedasticity

# TODO: ADD RESIDUALS TO DF, SORT BY DESIRED VARIABLE (or compare different orderings)

# preliminary analysis: plotting residuals
ggplot(data = res) + 
  aes(y = res, x = ind) + 
  geom_point() + 
  
  stat_smooth(method = 'lm', alpha = 0, formula = y~x)

#visual inspection suggesting very subtle downward trend, decreasing variance

#Goldfeld-Quandt test
gqtest(taylor_reg, point = 0.4, alternative = 'less')

#POINT = 0.2
# H0 is accepted with a p-val of 0.748 for test against H1: increasing variance, 
# still accepted but with a lower p-value (0.252) against H1. decreasing variance

#POINT = 0.4

#H0 is strongly rejected: we have a problem of heteroscedasticity


#since by BP test (see above) normality hold, we can also try the BP test:
#Breush-Pagan Test (taking output & inflation into consideration)
bptest(taylor_reg) # varformula = output + inflation

#the BP test does not reject H0 for significance levels <=0.01

#Testing Correlation of Residuals

# Durbin-Watson test for serial correlation 
dwtest(taylor_reg)

# Breusch-Godfrey test for serial correlation of order up to 3
bgtest(taylor_reg, 3)

# DW test strongly rejects H0,
# BG test (m = 3) rejects H0 down to alpha = 0.05.

# Strong indicators of serial correlation hint to a likely problem of omitted variables.
# ...hence we proceed to extend the model.

############################## EXTENDING THE MODEL ###############################

# Introduction of the 'UNEMPLOYMENT' regressor
unempl <- read.csv(paste(clean_path, '\\unemployment_rate.csv',sep = ''))
unempl = select(unempl, TIME, Value)
colnames(unempl) <- c('YEAR', 'UN')
unempl <- unempl[unempl$YEAR > 1984,]

df$UN <- unempl$UN

#Plotting the data
ggplot(unempl, aes(x = YEAR, y  = UN)) + 
  geom_point() + 
  labs(
    title = 'Australian Unemployment rate 1985-2020',
    x = ''
  ) +
  stat_smooth(method = 'lm', formula = y~x, alpha = 0.2)

#Run the regression

# GDP case
reg_un_1 <- lm(RATE ~ GDP + INF + UN, data = df)
summary(reg_un_1)
coeftest(reg_un_1)
# This way, the unemployment rate seems to be not statistically significant. The t-test has a p-value of 0.3131.

# GAP case
reg_un_2 <- lm(RATE ~ GAP + INF + UN, data = df)
summary(reg_un_2)
coeftest(reg_un_2)
# This way instead the unemployment rate is statistically significant. The t-test has a p-value of 1.448e-05.



# Introduction of the 'U.S. DOLLARS TO AUSTRALIAN DOLLARS SPOT EXCHANGE RATES' regressor
exc <- read.csv(paste(clean_path, '\\exchange_us.csv',sep = ''))
colnames(exc) <- c('YEAR', 'EXC')
exc <- exc[exc$YEAR > 1984,]

df$EXC <- exc$EXC

#Plotting the data
ggplot(exc, aes(x = YEAR, y  = EXC)) + 
  geom_point() + 
  labs(
    title = 'U.S. Dollars to Australian Dollar Spot Exchange Rate 1985-2020',
    x = ''
  ) +
  stat_smooth(method = 'lm', formula = y~x, alpha = 0.2)

#Run the regression

# GDP case
reg_exc_1 <- lm(RATE ~ GDP + INF + UN + EXC, data = df)
summary(reg_exc_1)
coeftest(reg_exc_1)

# GAP case
reg_exc_2 <- lm(RATE ~ GAP + INF + UN + EXC, data = df)
summary(reg_exc_2)
coeftest(reg_exc_2)



# Introduction of the 'AVERAGE COMMODITY PRICE INDEX ($A)' regressor
com <- read.csv(paste(clean_path, '\\commodity.csv',sep = ''))
colnames(com) <- c('YEAR', 'PRICE')
com <- com[com$YEAR > 1984,]
com <- na.omit(com)

df$COM <- com$PRICE

#Plotting the data
ggplot(com, aes(x = YEAR, y  = PRICE)) + 
  geom_point() + 
  labs(
    title = 'Average Commodity Price Index ($A) 1985-2020',
    x = ''
  ) +
  stat_smooth(method = 'lm', formula = y~x, alpha = 0.2)

#Run the regression

# GDP case
reg_com_1 <- lm(RATE ~ GDP + INF + EXC + UN + COM, data = df)
summary(reg_com_1)
coeftest(reg_com_1)

# GAP case
reg_com_2 <- lm(RATE ~ GAP + INF + COM + EXC, data = df)
summary(reg_com_2)
coeftest(reg_com_2)

# Possible additional variables

# US real interest rate
real <- read.csv(paste(clean_path, '\\US_real_rate%.csv',sep = ''))
colnames(real) <- c('YEAR', 'Rate')
real <- real[real$YEAR > 1984,]

#US 10-year Treasury yield
tres <- read.csv(paste(clean_path, '\\US10y_treasury.csv',sep = ''))
colnames(tres) <- c('YEAR', 'Rate')
tres <- tres[tres$YEAR > 1984,]



########################## ALTERNATIVE (GAP)  ############################

reg_1 = lm(RATE ~ GAP + INF, data = df)

summary(reg_1)

# output gap seems to be nonsignificant??

reg_2 = lm(RATE ~ GDP + INF, data = df)

summary(reg_2)





######################### DYNAMIC VERSION ####################################


# Adding lagged interest rates to the dataframe
# IMPORTANT: The first term is simply set to the same year value

rr = df['RATE']
rr_shifted <- c(rr$RATE[1],rr$RATE[1:35])
df$SHIFTED_RATE <- rr_shifted


# IMPORTANT: DO NOT USE DW TEST


reg_dynamic <- lm(RATE ~ SHIFTED_RATE + GAP + INF, data = df)

summary(reg_dynamic)

# TESTING FOR AUTOCORRELATION

bgtest(reg_dynamic, 3)

# introducing lagged interest rates seems to solve any problem of
# autocorrelation up to order 3

# TODO: implement remaining tests, make comparisons
# TODO: test for





#TODO - Variable Selection
# pick features
# wages? (correlation with output gap)
# foreign interest rates?
# lagged interest rates? (dynamic model, issues with testing)
# forward/backward pass
